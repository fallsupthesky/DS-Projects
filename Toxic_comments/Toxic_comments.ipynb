{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Токсичные комментарии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на выборку 10 случайных строк:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>126428</td>\n",
       "      <td>What is best for the article is probably best ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121506</td>\n",
       "      <td>That official BBC link refers to it as series ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51931</td>\n",
       "      <td>\"\\n Hello, , and Welcome to Wikipedia!\\nPlease...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31704</td>\n",
       "      <td>Oppose The current redirects and intro do the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78408</td>\n",
       "      <td>I promise you the first thing I will do is hav...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143750</td>\n",
       "      <td>\"*:*:*Or we can do a search on \"\"the Wilhelmst...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42176</td>\n",
       "      <td>DYK peer review?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94850</td>\n",
       "      <td>Edit request on 26 November 2012 \\n\\nhttp://ww...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90473</td>\n",
       "      <td>\"\\nYour hairsplitting distinction between \"\"ru...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147279</td>\n",
       "      <td>This page was nominated for deletion at Wikipe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "126428  What is best for the article is probably best ...      0\n",
       "121506  That official BBC link refers to it as series ...      0\n",
       "51931   \"\\n Hello, , and Welcome to Wikipedia!\\nPlease...      0\n",
       "31704   Oppose The current redirects and intro do the ...      0\n",
       "78408   I promise you the first thing I will do is hav...      0\n",
       "143750  \"*:*:*Or we can do a search on \"\"the Wilhelmst...      0\n",
       "42176                                    DYK peer review?      0\n",
       "94850   Edit request on 26 November 2012 \\n\\nhttp://ww...      0\n",
       "90473   \"\\nYour hairsplitting distinction between \"\"ru...      0\n",
       "147279  This page was nominated for deletion at Wikipe...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всего в файле 159571 записей, 2 столбца."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>159571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.101679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.302226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic\n",
       "count  159571.000000\n",
       "mean        0.101679\n",
       "std         0.302226\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.000000\n",
       "max         1.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Токсичных\" записей всего около 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дублированных строк нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим функцию и удалим лишние символы из данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    string = re.sub(r'[^a-zA-Z]',' ', text)\n",
    "    string = string.split()\n",
    "    string = \" \".join(string)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data['text'] = data['text'].apply(clear_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним лемматизацию с помощью wordnet NLTK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install nltk\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemm(text):\n",
    "\n",
    "    list = nltk.word_tokenize(text)\n",
    "    lemmatized_string = ' '.join([wnl.lemmatize(words) for words in list])\n",
    "    \n",
    "    return lemmatized_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data['lemm_text'] = data['text'].apply(lemm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные на тренировочную и тестовую выборки в соотношении 80/20%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_split(data, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = data_train['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = data_test['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train = data_train['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_test = data_test['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train = features_train.values.astype('U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_test = features_test.values.astype('U')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем кодирование текста с помощью TF-IDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tf_idf_train = count_tf_idf.fit_transform(corpus_train)\n",
    "\n",
    "tf_idf_test = count_tf_idf.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном этапе был загружен файл с данными \"toxic_comments.csv\". В файле имеется 159571 запись, 2 столбца с текстом твитов и целевым признаком \"toxic\". Записей с целевым признаком \"1\" около 10% всех данных. Дублированные строки отсутствуют. Из текста были удалены символы, отличные от букв латинского алфавита. Далее текст твитов был лемматизирован, данные разделены на тренировочную и тестовую выборки и преобразованы с помощью TF-IDF Vectorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдем оптимальные параметры для моделей логистической регрессии, решающего дерева, случайного леса, LightGBM при помощи GridSearchCV и найдем значение F1-score на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим таблицу для результатов f1 моделей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = pd.DataFrame(\n",
    "    columns=['f1_train', 'f1_test'], \n",
    "    index=['logistic_regression', 'decision_tree', 'random_forest', 'LightGBM']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ищем оптимальные параметры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_regression = LogisticRegression(solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_regression = {\n",
    "    'solver': ['lbfgs'],\n",
    "    'C': [17.5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_regression = GridSearchCV(model_regression, params_regression, cv=3, scoring='f1', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.54 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pavel\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'C': [17.5], 'solver': ['lbfgs']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "grid_regression.fit(tf_idf_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7638917143677643"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_regression.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 17.5, 'solver': 'lbfgs'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_regression.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results.loc['logistic_regression', 'f1_train'] = round(grid_regression.best_score_, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модель и проверяем на тестовых данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_regression = LogisticRegression(\n",
    "    \n",
    "    solver = grid_regression.best_params_['solver'], \n",
    "    C = grid_regression.best_params_['C']\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.19 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pavel\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=17.5, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_regression.fit(tf_idf_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.01 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions_regression = model_regression.predict(tf_idf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7795123662515347"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_regression = f1_score(target_test, predictions_regression)\n",
    "f1_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results.loc['logistic_regression', 'f1_test'] = round(f1_regression, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Дерево решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Находим оптимальные параметры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tree = DecisionTreeClassifier(random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_tree = {\n",
    "    'max_depth': [100],\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [1] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_tree = GridSearchCV(model_tree, params_tree, cv=3, scoring='f1', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 32s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort=False, random_state=1234,\n",
       "                                              splitter='best'),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'max_depth': [100], 'min_samples_leaf': [1],\n",
       "                         'min_samples_split': [2]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "grid_tree.fit(tf_idf_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7161854050762234"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_tree.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 2}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_tree.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results.loc['decision_tree', 'f1_train'] = round(grid_tree.best_score_, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модель и проверяем на тестовых данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tree = DecisionTreeClassifier(\n",
    "    \n",
    "    random_state=1234,\n",
    "    max_depth = grid_tree.best_params_['max_depth'],\n",
    "    min_samples_split = grid_tree.best_params_['min_samples_split'],\n",
    "    min_samples_leaf = grid_tree.best_params_['min_samples_leaf']\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 51.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=100,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=1234, splitter='best')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_tree.fit(tf_idf_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_tree = model_tree.predict(tf_idf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7308693388859968"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_tree = f1_score(target_test, predictions_tree)\n",
    "f1_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results.loc['decision_tree', 'f1_test'] = round(f1_tree, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Случайный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Находим оптимальные параметры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_forest = RandomForestClassifier(random_state=1234, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_forest = {\n",
    "    'max_depth': [500],\n",
    "    'n_estimators': [10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_forest = GridSearchCV(model_forest, params_forest, cv=3, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=-1,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=1234, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'max_depth': [500], 'n_estimators': [10]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "grid_forest.fit(tf_idf_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.660115030896057"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_forest.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 500, 'n_estimators': 10}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_forest.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results.loc['random_forest', 'f1_train'] = round(grid_forest.best_score_, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модель и проверяем на тестовых данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_forest = RandomForestClassifier(\n",
    "    \n",
    "    random_state=1234,\n",
    "    max_depth = grid_forest.best_params_['max_depth'],\n",
    "    n_estimators = grid_forest.best_params_['n_estimators']\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 44.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=500, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=1234,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_forest.fit(tf_idf_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_forest = model_forest.predict(tf_idf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6847632256786209"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_forest = f1_score(target_test, predictions_forest)\n",
    "f1_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results.loc['random_forest', 'f1_test'] = round(f1_forest, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим признаки для обучения модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(tf_idf_train, target_train)\n",
    "lgb_test = lgb.Dataset(tf_idf_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запускаем LightGBM в GridSearch для поиска оптимальных параметров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridParams = {\n",
    "    \n",
    "    'n_estimators': [10], \n",
    "    'max_depth': [29], \n",
    "    'learning_rate': [0.35], \n",
    "    'reg_alpha': [0.1],\n",
    "    'reg_lambda': [0.02]\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = lgb.LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_GBM = GridSearchCV(gbm, gridParams, cv=3, scoring='f1', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Wall time: 24.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
       "                                      colsample_bytree=1.0,\n",
       "                                      importance_type='split',\n",
       "                                      learning_rate=0.1, max_depth=-1,\n",
       "                                      min_child_samples=20,\n",
       "                                      min_child_weight=0.001,\n",
       "                                      min_split_gain=0.0, n_estimators=100,\n",
       "                                      n_jobs=-1, num_leaves=31, objective=None,\n",
       "                                      random_state=None, reg_alpha=0.0,\n",
       "                                      reg_lambda=0.0, silent=True,\n",
       "                                      subsample=1.0, subsample_for_bin=200000,\n",
       "                                      subsample_freq=0),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.35], 'max_depth': [29],\n",
       "                         'n_estimators': [10], 'reg_alpha': [0.1],\n",
       "                         'reg_lambda': [0.02]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "grid_GBM.fit(tf_idf_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.35,\n",
       " 'max_depth': 29,\n",
       " 'n_estimators': 10,\n",
       " 'reg_alpha': 0.1,\n",
       " 'reg_lambda': 0.02}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_GBM.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6958488745984188"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_GBM.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results.loc['LightGBM', 'f1_train'] = round(grid_GBM.best_score_, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Обучаем модель и проверяем на тестовых данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \n",
    "    'objective': 'binary',\n",
    "    'metric': 'f1',\n",
    "    'learning_rate': grid_GBM.best_params_['learning_rate'],\n",
    "    'n_estimators': grid_GBM.best_params_['n_estimators'],\n",
    "    'max_depth': grid_GBM.best_params_['max_depth'],\n",
    "    'reg_alpha': grid_GBM.best_params_['reg_alpha'],\n",
    "    'reg_lambda': grid_GBM.best_params_['reg_lambda'],\n",
    "    'verbose': -1\n",
    "    \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pavel\\anaconda3\\envs\\practicum\\lib\\site-packages\\lightgbm\\engine.py:151: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "gbm = lgb.train(\n",
    "    \n",
    "    params, \n",
    "    lgb_train, \n",
    "    valid_sets=lgb_test, \n",
    "    verbose_eval=False\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 81.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions_lgb = gbm.predict(tf_idf_test, num_iteration=gbm.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lgb = (predictions_lgb.round(0)).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.711017112093828"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_lgb = f1_score(target_test, predictions_lgb)\n",
    "f1_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results.loc['LightGBM', 'f1_test'] = round(f1_lgb, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном этапе было проведен поиск параметров по сетке с помощью GridSearchCV моделей логистической регрессии, решающего дерева, случайного леса, LightGBM с кол.-вом folds равным 3 и метрикой f1-score. По найденным оптимальным гиперпараметрам были обучены соответствующие модели и получены предсказания на тестовых данных. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на значения f1 моделей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_train</th>\n",
       "      <th>f1_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    f1_train f1_test\n",
       "logistic_regression    0.764    0.78\n",
       "decision_tree          0.716   0.731\n",
       "LightGBM               0.696   0.711\n",
       "random_forest           0.66   0.685"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results.sort_values(by='f1_test', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучшие результаты показали модели логистической регрессии и решающего дерева - значение f1 на тестовых данных составляет 0.781 и 0.731 соответственно. При этом время обучения и предсказания решающего дерева намного больше времени, которое необходимо логистической регрессии. Худшие результаты показали модели LightGBM и случайный лес - значения их f1 ниже порога в 0.75. Т.о., в сервисе \"Викишоп\" для оптимального соотношения качества предсказаний и затраченного времени рекомендуется использовать логистическую регрессию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Данные загружены и подготовлены\n",
    "- [x]  Модели обучены\n",
    "- [x]  Значение метрики *F1* не меньше 0.75\n",
    "- [x]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 2142,
    "start_time": "2022-04-22T05:42:29.393Z"
   },
   {
    "duration": 7260,
    "start_time": "2022-04-22T05:42:31.538Z"
   },
   {
    "duration": 33,
    "start_time": "2022-04-22T05:42:38.800Z"
   },
   {
    "duration": 39,
    "start_time": "2022-04-22T05:42:38.837Z"
   },
   {
    "duration": 48,
    "start_time": "2022-04-22T05:42:38.878Z"
   },
   {
    "duration": 299,
    "start_time": "2022-04-22T05:42:38.928Z"
   },
   {
    "duration": 4,
    "start_time": "2022-04-22T05:42:39.229Z"
   },
   {
    "duration": 5713,
    "start_time": "2022-04-22T05:42:39.235Z"
   },
   {
    "duration": 3,
    "start_time": "2022-04-22T05:42:44.950Z"
   },
   {
    "duration": 9,
    "start_time": "2022-04-22T05:42:44.957Z"
   },
   {
    "duration": 9,
    "start_time": "2022-04-22T05:42:44.968Z"
   },
   {
    "duration": 128309,
    "start_time": "2022-04-22T05:42:44.979Z"
   },
   {
    "duration": 79,
    "start_time": "2022-04-22T05:44:53.291Z"
   },
   {
    "duration": 5,
    "start_time": "2022-04-22T05:44:53.372Z"
   },
   {
    "duration": 23,
    "start_time": "2022-04-22T05:44:53.380Z"
   },
   {
    "duration": 24,
    "start_time": "2022-04-22T05:44:53.406Z"
   },
   {
    "duration": 15,
    "start_time": "2022-04-22T05:44:53.432Z"
   },
   {
    "duration": 2126,
    "start_time": "2022-04-22T05:44:53.449Z"
   },
   {
    "duration": 610,
    "start_time": "2022-04-22T05:44:55.578Z"
   },
   {
    "duration": 8,
    "start_time": "2022-04-22T05:44:56.190Z"
   },
   {
    "duration": 25,
    "start_time": "2022-04-22T05:44:56.200Z"
   },
   {
    "duration": 4,
    "start_time": "2022-04-22T05:44:56.227Z"
   },
   {
    "duration": 13693,
    "start_time": "2022-04-22T05:44:56.233Z"
   },
   {
    "duration": 6,
    "start_time": "2022-04-22T05:45:09.929Z"
   },
   {
    "duration": 10,
    "start_time": "2022-04-22T05:45:09.938Z"
   },
   {
    "duration": 14,
    "start_time": "2022-04-22T05:45:09.950Z"
   },
   {
    "duration": 11,
    "start_time": "2022-04-22T05:45:09.966Z"
   },
   {
    "duration": 218844,
    "start_time": "2022-04-22T05:45:09.983Z"
   },
   {
    "duration": 6,
    "start_time": "2022-04-22T05:48:48.829Z"
   },
   {
    "duration": 8,
    "start_time": "2022-04-22T05:48:48.837Z"
   },
   {
    "duration": 7,
    "start_time": "2022-04-22T05:48:48.848Z"
   },
   {
    "duration": 11,
    "start_time": "2022-04-22T05:48:48.857Z"
   },
   {
    "duration": 57862,
    "start_time": "2022-04-22T05:48:48.870Z"
   },
   {
    "duration": 94,
    "start_time": "2022-04-22T05:49:46.735Z"
   },
   {
    "duration": 19,
    "start_time": "2022-04-22T05:49:46.831Z"
   },
   {
    "duration": 5,
    "start_time": "2022-04-22T05:49:46.852Z"
   },
   {
    "duration": 5,
    "start_time": "2022-04-22T05:49:46.859Z"
   },
   {
    "duration": 11,
    "start_time": "2022-04-22T05:49:46.866Z"
   },
   {
    "duration": 49,
    "start_time": "2022-04-22T05:49:46.880Z"
   },
   {
    "duration": 297976,
    "start_time": "2022-04-22T05:49:46.931Z"
   },
   {
    "duration": 17,
    "start_time": "2022-04-22T05:54:44.909Z"
   },
   {
    "duration": 11,
    "start_time": "2022-04-22T05:54:44.928Z"
   },
   {
    "duration": 6,
    "start_time": "2022-04-22T05:54:44.941Z"
   },
   {
    "duration": 8,
    "start_time": "2022-04-22T05:54:44.949Z"
   },
   {
    "duration": 98155,
    "start_time": "2022-04-22T05:54:44.959Z"
   },
   {
    "duration": 37,
    "start_time": "2022-04-22T05:56:23.116Z"
   },
   {
    "duration": 17,
    "start_time": "2022-04-22T05:56:23.155Z"
   },
   {
    "duration": 4,
    "start_time": "2022-04-22T05:56:23.174Z"
   },
   {
    "duration": 8,
    "start_time": "2022-04-22T05:56:23.180Z"
   },
   {
    "duration": 37,
    "start_time": "2022-04-22T05:56:23.190Z"
   },
   {
    "duration": 7,
    "start_time": "2022-04-22T05:56:23.229Z"
   },
   {
    "duration": 276063,
    "start_time": "2022-04-22T05:56:23.238Z"
   },
   {
    "duration": 5,
    "start_time": "2022-04-22T06:00:59.303Z"
   },
   {
    "duration": 9,
    "start_time": "2022-04-22T06:00:59.325Z"
   },
   {
    "duration": 9,
    "start_time": "2022-04-22T06:00:59.336Z"
   },
   {
    "duration": 11,
    "start_time": "2022-04-22T06:00:59.347Z"
   },
   {
    "duration": 58585,
    "start_time": "2022-04-22T06:00:59.360Z"
   },
   {
    "duration": 550,
    "start_time": "2022-04-22T06:01:57.947Z"
   },
   {
    "duration": 25,
    "start_time": "2022-04-22T06:01:58.500Z"
   },
   {
    "duration": 4,
    "start_time": "2022-04-22T06:01:58.527Z"
   },
   {
    "duration": 11,
    "start_time": "2022-04-22T06:01:58.533Z"
   },
   {
    "duration": 12,
    "start_time": "2022-04-22T06:01:58.546Z"
   },
   {
    "duration": 11,
    "start_time": "2022-04-22T06:01:58.560Z"
   },
   {
    "duration": 7,
    "start_time": "2022-04-22T06:01:58.574Z"
   },
   {
    "duration": 2105,
    "start_time": "2022-04-22T06:05:46.466Z"
   },
   {
    "duration": 5131,
    "start_time": "2022-04-22T06:05:48.573Z"
   },
   {
    "duration": 36,
    "start_time": "2022-04-22T06:05:53.706Z"
   },
   {
    "duration": 43,
    "start_time": "2022-04-22T06:05:53.744Z"
   },
   {
    "duration": 44,
    "start_time": "2022-04-22T06:05:53.790Z"
   },
   {
    "duration": 328,
    "start_time": "2022-04-22T06:05:53.837Z"
   },
   {
    "duration": 6,
    "start_time": "2022-04-22T06:05:54.168Z"
   },
   {
    "duration": 5887,
    "start_time": "2022-04-22T06:05:54.176Z"
   },
   {
    "duration": 4,
    "start_time": "2022-04-22T06:06:00.065Z"
   },
   {
    "duration": 35,
    "start_time": "2022-04-22T06:06:00.071Z"
   },
   {
    "duration": 24,
    "start_time": "2022-04-22T06:06:00.109Z"
   },
   {
    "duration": 126947,
    "start_time": "2022-04-22T06:06:00.136Z"
   },
   {
    "duration": 114,
    "start_time": "2022-04-22T06:08:07.086Z"
   },
   {
    "duration": 5,
    "start_time": "2022-04-22T06:08:07.215Z"
   },
   {
    "duration": 7,
    "start_time": "2022-04-22T06:08:07.222Z"
   },
   {
    "duration": 9,
    "start_time": "2022-04-22T06:08:07.232Z"
   },
   {
    "duration": 9,
    "start_time": "2022-04-22T06:08:07.244Z"
   },
   {
    "duration": 2032,
    "start_time": "2022-04-22T06:08:07.255Z"
   },
   {
    "duration": 521,
    "start_time": "2022-04-22T06:08:09.289Z"
   },
   {
    "duration": 13,
    "start_time": "2022-04-22T06:08:09.812Z"
   },
   {
    "duration": 15,
    "start_time": "2022-04-22T06:08:09.827Z"
   },
   {
    "duration": 13,
    "start_time": "2022-04-22T06:08:09.844Z"
   },
   {
    "duration": 13383,
    "start_time": "2022-04-22T06:08:09.859Z"
   },
   {
    "duration": 6,
    "start_time": "2022-04-22T06:08:23.244Z"
   },
   {
    "duration": 17,
    "start_time": "2022-04-22T06:08:23.252Z"
   },
   {
    "duration": 6,
    "start_time": "2022-04-22T06:08:23.271Z"
   },
   {
    "duration": 6,
    "start_time": "2022-04-22T06:08:23.279Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
